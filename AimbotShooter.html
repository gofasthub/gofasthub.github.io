<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Plixys Tuff Assistant</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Load Lucide Icons for aesthetic buttons -->
    <script src="https://unpkg.com/lucide@latest"></script>
    <style>
        /* Define the new theme colors (Deep Teal/Cyan) */
        :root {
            --color-accent: #20c997; /* Teal/Mint for highlight */
            --color-accent-dark: #12b886; /* Darker accent for buttons */
            --color-bg-dark: #0f172a; /* Slate-900 or near black for body */
            --color-bg-container: #1e293b; /* Slate-800 for container */
            --color-bg-input: #334155; /* Slate-700 for input */
            --color-text-light: #f1f5f9; /* Slate-100 */
        }
        
        /* Apply background and font for the body */
        body {
            background-color: var(--color-bg-dark);
        }

        /* Custom scrollbar styling for a cleaner look */
        #chat-window::-webkit-scrollbar {
            width: 8px;
        }
        #chat-window::-webkit-scrollbar-thumb {
            background-color: var(--color-accent-dark);
            border-radius: 4px;
        }
        #chat-window::-webkit-scrollbar-track {
            background-color: var(--color-bg-container);
        }
        
        /* Style for the sender (user) messages */
        .user-message {
            background-color: var(--color-accent);
            color: #0f172a; /* Dark text for contrast on bright bubble */
            border-bottom-right-radius: 0;
            align-self: flex-end;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.2), 0 2px 4px -2px rgba(0, 0, 0, 0.1);
        }
        /* Style for the AI messages */
        .ai-message {
            background-color: var(--color-bg-input); /* Use input color for AI bubble */
            color: var(--color-text-light);
            border-bottom-left-radius: 0;
            align-self: flex-start;
            box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
        }
    </style>
</head>
<body class="text-white font-sans flex items-center justify-center min-h-screen p-4">

    <!-- Container updated to use the new color and enhanced styling -->
    <div class="w-full max-w-xl bg-slate-800 rounded-2xl shadow-2xl flex flex-col h-[80vh] overflow-hidden border border-slate-700/50">
        
        <!-- Header with Model Selector -->
        <header class="p-4 bg-slate-700/50 border-b border-teal-500/50 flex justify-between items-center">
            <div>
                <h1 class="text-2xl font-bold text-teal-400 flex items-center">
                    <i data-lucide="brain-circuit" class="w-6 h-6 mr-2"></i>
                    Plixys Tuff Assistant
                </h1>
                <p class="text-xs text-slate-400 mt-1">Ask me anything!</p>
            </div>
            <div class="flex flex-col items-end">
                <label for="model-selector" class="text-xs text-slate-400 mb-1">Model:</label>
                <!-- Updated selector: Pro model removed -->
                <select id="model-selector" class="bg-slate-700 text-slate-200 p-2 rounded-xl border border-slate-600 text-sm focus:ring-teal-500 focus:border-teal-500 cursor-pointer transition duration-150" title="Select the model to use for generation">
                    <option value="gemini-2.5-flash-preview-09-2025">Flash (Standard)</option>
                    <option value="gemini-2.5-flash-grounded">Flash (Web Search)</option>
                </select>
            </div>
        </header>

        <!-- Chat Window -->
        <div id="chat-window" class="flex-grow p-4 space-y-4 overflow-y-auto" style="background-color: var(--color-bg-container);">
            <!-- Initial welcome message -->
            <div class="max-w-[80%] p-3 rounded-xl ai-message shadow-lg mb-2">
                Hello! I'm your digital assistant. How can I help you today?
            </div>
            <!-- Messages will be injected here -->
        </div>

        <!-- Loading Indicator -->
        <div id="loading-indicator" class="px-4 py-2 text-teal-400 text-sm italic hidden">
            <i data-lucide="loader-circle" class="w-4 h-4 mr-1 inline animate-spin"></i>
            Assistant is typing...
        </div>

        <!-- Input Form -->
        <div class="p-4 border-t border-slate-700/50">
            <form id="chat-form" class="flex space-x-3">
                <input type="text" id="user-input" placeholder="Type your message..." required 
                       class="flex-grow p-3 rounded-xl bg-slate-700 border border-slate-600 focus:ring-2 focus:ring-teal-500 focus:border-teal-500 text-slate-200 placeholder-slate-400 transition duration-150 shadow-inner"
                       style="background-color: var(--color-bg-input);">
                <button type="submit" id="send-button" 
                        class="bg-teal-600 hover:bg-teal-500 text-white p-3 rounded-xl shadow-lg transition duration-150 flex items-center justify-center disabled:opacity-50 disabled:cursor-not-allowed transform hover:scale-[1.02] active:scale-[0.98] focus:outline-none focus:ring-2 focus:ring-teal-500 focus:ring-offset-2 focus:ring-offset-slate-800"
                        style="background-color: var(--color-accent-dark);">
                    <i data-lucide="send" class="w-5 h-5"></i>
                </button>
            </form>
        </div>
        
        <!-- API Key info (must be present for API calls) -->
        <span id="api-key-status" class="text-xs text-center text-red-500 p-1 hidden"></span>
    </div>

    <script>
        // Ensure Lucide icons are rendered after the HTML is loaded
        lucide.createIcons();

        // --- Configuration and Constants ---
        const MAX_RETRIES = 5;
        const INITIAL_BACKOFF_MS = 1000;
        
        // Use the global API key provided by the environment, or leave empty if not present.
        const apiKey = (typeof __api_key !== 'undefined' ? __api_key : ""); 

        const chatWindow = document.getElementById('chat-window');
        const chatForm = document.getElementById('chat-form');
        const userInput = document.getElementById('user-input');
        const sendButton = document.getElementById('send-button');
        const loadingIndicator = document.getElementById('loading-indicator');
        const modelSelector = document.getElementById('model-selector');

        let chatHistory = [];
        let currentModel = modelSelector.value; // Initialize currentModel

        // Event listener for model change to clear history and update model
        modelSelector.addEventListener('change', (e) => {
            currentModel = e.target.value;
            chatHistory = []; // Clear history when model changes
            
            // Display a message acknowledging the model change
            const modelName = e.target.options[e.target.selectedIndex].text;
            chatWindow.innerHTML = '<div class="max-w-[80%] p-3 rounded-xl ai-message shadow-md mb-2">Model switched to **' + modelName + '**! How can I assist you?</div>';
            chatWindow.scrollTop = chatWindow.scrollHeight;
        });
        
        // System instruction to define the AI's role and tone
        const systemInstruction = "You are Plixys Tuff Assistant, a friendly, witty, and highly knowledgeable digital assistant. Keep your responses concise and helpful.";

        // --- UI Functions ---

        function appendMessage(role, text, sources = []) {
            const messageElement = document.createElement('div');
            messageElement.className = `max-w-[80%] p-3 rounded-xl shadow-lg whitespace-pre-wrap mb-2`;
            
            // Apply role-specific styling
            if (role === 'user') {
                messageElement.classList.add('user-message');
            } else {
                messageElement.classList.add('ai-message');
                // Basic Markdown conversion
                text = text.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
                text = text.replace(/\*(.*?)\*/g, '<em>$1</em>');
                
                // Add citations if present
                if (sources.length > 0) {
                    const citationsHtml = sources.map((source, index) => 
                        `<a href="${source.uri}" target="_blank" class="text-xs text-teal-300 hover:text-teal-200 underline">${index + 1}. ${source.title || 'Source'}</a>`
                    ).join('<br>');

                    text += `<div class="mt-3 pt-3 border-t border-slate-600 text-xs text-slate-400">Sources:<br>${citationsHtml}</div>`;
                }
            }

            messageElement.innerHTML = text;
            chatWindow.appendChild(messageElement);
            // Auto-scroll to the bottom of the chat window
            chatWindow.scrollTop = chatWindow.scrollHeight;
        }

        function toggleLoading(isLoading) {
            sendButton.disabled = isLoading;
            userInput.disabled = isLoading;
            if (isLoading) {
                loadingIndicator.classList.remove('hidden');
                lucide.createIcons(); // Re-render the spinning icon
            } else {
                loadingIndicator.classList.add('hidden');
            }
        }

        // --- API & Core Logic ---

        // Function to make the API call with exponential backoff
        async function fetchWithRetry(url, options, retries = MAX_RETRIES) {
            for (let i = 0; i < retries; i++) {
                try {
                    const response = await fetch(url, options);
                    
                    // Handle non-2xx status codes (including 400s like model not found)
                    if (response.status !== 200) {
                        const errorJson = await response.json();
                        
                        // Check if this is a model or connection issue that might warrant a retry
                        if (response.status === 429 || (response.status >= 500 && response.status < 600)) {
                             if (i < retries - 1) {
                                const delay = INITIAL_BACKOFF_MS * Math.pow(2, i) + Math.random() * 1000;
                                await new Promise(resolve => setTimeout(resolve, delay));
                                continue; // Retry
                            }
                        }
                        // For non-retryable errors or final attempt failure
                        throw new Error(`API Error ${response.status}: ${errorJson.error?.message || JSON.stringify(errorJson)}`);
                    }

                    // Successful response
                    return await response.json();

                } catch (error) {
                    console.error("Fetch attempt failed:", error);
                    if (i === retries - 1) {
                        throw new Error(`Failed to connect to the model after ${MAX_RETRIES} attempts. Error: ${error.message}`);
                    }
                }
            }
        }

        async function generateResponse(prompt) {
            const userContent = { role: "user", parts: [{ text: prompt }] };
            chatHistory.push(userContent);

            const payload = {
                contents: chatHistory,
                systemInstruction: { parts: [{ text: systemInstruction }] }
            };

            let modelForApi = currentModel;

            // Determine if grounding is needed and set the model/tools accordingly
            if (currentModel === 'gemini-2.5-flash-grounded') {
                // Use the sanctioned preview model name for API calls when grounding is requested
                modelForApi = 'gemini-2.5-flash-preview-09-2025'; 
                payload.tools = [{ "google_search": {} }];
            }

            try {
                // Dynamically build the API endpoint based on the determined model
                const API_ENDPOINT = `https://generativelanguage.googleapis.com/v1beta/models/${modelForApi}:generateContent`;
                
                let url = API_ENDPOINT;
                // FIX: Only append the API key if it's available, otherwise the environment handles it.
                if (apiKey) {
                    url += `?key=${apiKey}`;
                }
                
                const result = await fetchWithRetry(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const candidate = result.candidates?.[0];
                const generatedText = candidate?.content?.parts?.[0]?.text;

                let sources = [];
                const groundingMetadata = candidate?.groundingMetadata;
                if (groundingMetadata && groundingMetadata.groundingAttributions) {
                    sources = groundingMetadata.groundingAttributions
                        .map(attribution => ({
                            uri: attribution.web?.uri,
                            title: attribution.web?.title,
                        }))
                        .filter(source => source.uri && source.title); 
                }


                if (generatedText) {
                    // Only store the text part in history, not the citations
                    const assistantContent = { role: "model", parts: [{ text: generatedText }] };
                    chatHistory.push(assistantContent);
                    return { text: generatedText, sources: sources };
                } else {
                    return { text: "Sorry, I received an empty response. Please try again.", sources: [] };
                }

            } catch (error) {
                console.error("Gemini API call failed:", error);
                // Remove the user message from history if the call failed
                chatHistory.pop(); 
                // Display the error in the chat window for immediate user feedback
                return { text: `An error occurred: ${error.message}. This is likely a connection or authentication problem. Please try again or check your console for details.`, sources: [] };
            }
        }

        // --- Event Listener ---

        chatForm.addEventListener('submit', async (e) => {
            e.preventDefault();
            const prompt = userInput.value.trim();
            if (!prompt) return;

            // 1. Display user message
            appendMessage('user', prompt);
            userInput.value = '';
            
            // 2. Show loading and disable input
            toggleLoading(true);

            // 3. Get AI response
            const response = await generateResponse(prompt);

            // 4. Display AI response with citations
            appendMessage('ai', response.text, response.sources);

            // 5. Hide loading and enable input
            toggleLoading(false);
        });

    </script>
</body>
</html>
